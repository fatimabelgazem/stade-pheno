# üß™ 4 - √âvaluation du Mod√®le

Cette section d√©taille le processus d'√©valuation de notre mod√®le entra√Æn√© pour la d√©tection des stades ph√©nologiques des orangers. L'√©valuation est une √©tape critique du cycle MLOps qui permet de valider les performances et la fiabilit√© du mod√®le avant son d√©ploiement.

## 3.1 - M√©thodologie d'√©valuation

Notre √©valuation suit une approche rigoureuse bas√©e sur plusieurs m√©triques compl√©mentaires :

- **üìä Dataset de test :** 10% de notre jeu de donn√©es total, r√©serv√© sp√©cifiquement pour l'√©valuation
- **üéØ M√©triques principales :** mAP (mean Average Precision), Pr√©cision, Rappel, F1-Score
- **üîÑ Validation crois√©e :** Pour garantir la robustesse des r√©sultats.
L'√©valuation est r√©alis√©e de mani√®re ind√©pendante de l'entra√Ænement, conform√©ment aux bonnes pratiques MLOps, assurant ainsi l'int√©grit√© des r√©sultats.

## ‚öôÔ∏è 3.2 - Configuration de l'√©valuation

Pour √©valuer notre mod√®le, nous avons utilis√© le mode val de YOLOv8 avec suivi via MLflow :
```bash
import mlflow
import os
import pandas as pd

# Initialisation de MLflow pour l'√©valuation
mlflow.set_tracking_uri("file:///kaggle/working/mlruns")
mlflow.set_experiment("YOLOv8_StadePheno1_Evaluation")

with mlflow.start_run(run_name="evaluation_final_model") as run:
    # Log des param√®tres d'√©valuation
    mlflow.log_param("model_path", "/kaggle/working/datasets/runs/detect/train/weights/best.pt")
    mlflow.log_param("imgsz", 800)
    
    # Lancement de l'√©valuation
    !yolo task=detect mode=val \
        model=/kaggle/working/datasets/runs/detect/train/weights/best.pt \
        data=/kaggle/working/datasets/Stade_Pheno_Dataset-3/data.yaml \
        imgsz=800

```

## üìä 3.3 - R√©sultats de l'√©valuation
L'√©valuation de notre mod√®le a donn√© d'excellents r√©sultats sur le jeu de donn√©es de test :
### üìâ M√©triques globales :

| M√©trique     | Valeur      | Description                                       |
|--------------|-------------|---------------------------------------------------|
|   mAP50      |  0.877      |  Pr√©cision moyenne √† 50% IoU                      |
|  mAP50-95    |  0.618      |  Pr√©cision moyenne entre 50% et 95% IoU           |
|  Precision   |  0.87       |  Pr√©cision globale du mod√®le                      |
|  Recall      |  0.81       |  Rappel global du mod√®le                          |
|  F1-Score    |  0.84       |  Moyenne harmonique de la pr√©cision et du rappel  |

###  Performance par classe :
 
|   Classe        |  Label  |  mAP50  |  Precision  |  Recall           |
|-----------------|---------|---------|-------------|-------------------|
|   Flower        |    0    |  0.872  |    0.897    |       0.751       |
|   Flower Fermee |    1    |  0.877  |    0.814    |       0.816       |
|   Green         |    2    |  0.929  |    0.896    |       0.877       |
|   Mature        |    3    |  0.886  |   0.952     |       0.83        |
|   Noisant       |    4    |  0.823  |    0.79     |       0.778       |         




### üîÑ Matrice de confusion :
<p align="center">
  <img src={require('/static/img/MLops/Confusion Matrix.png').default} alt="Matrice de confusion" width="600px" />
</p>

La matrice de confusion montre une bonne classification pour toutes les classes, avec peu de confusions entre les diff√©rentes cat√©gories.


## üñºÔ∏è 3.4 - Visualisation des pr√©dictions

Pour une √©valuation qualitative, nous avons observ√© les pr√©dictions du mod√®le sur des images de test :

<div style={{ display: "flex", justifyContent: "space-around", alignItems: "center", flexWrap: "wrap" }}>
  <div style={{ textAlign: "center", width: "65%" }}>
    <img src={require('/static/img/MLops/merged_resul2.jpg').default} alt="Exemple de pr√©diction 1" style={{ maxWidth: "95%", borderRadius: "10px" }} />
    <p><strong>D√©tection des fruits fruits matures,flower et flower fermee</strong></p>
  </div>
 
</div>

 ### üß™ Analyse des erreurs :
Nous avons √©galement identifi√© les cas typiques d'erreurs du mod√®le :

|   Type d'erreur                                 |    Fr√©quence    |    Cause probable               |
|-------------------------------------------------|-----------------|---------------------------------|
|   Faux n√©gatifs (fruits non d√©tect√©s)           |      12%        |    Occlusion par les feuilles   |
|   Confusion entre fruits verts et le backgound  |       8%        |    Variations de luminosit√©     |
|   D√©tections multiples du m√™me fruit            |       5%        |    Seuil IoU trop bas           |

## ‚úÖ 3.6 - R√©sum√© de l'√©valuation

|      √âtape               |        Action r√©alis√©e                                   |
|--------------------------|---------------------------------------------------|
|  Mod√®le de base          |  YOLOv8m pr√©-entra√Æn√© sur "Nature3: Leaf, Flower, and Fruit Detection"                   |
|  Fine-tuning             |  Entra√Ænement sur notre dataset d'orangers pendant 100 epochs                            |
|  Suivi                   |  MLflow pour la tra√ßabilit√© des exp√©riences et des m√©triques                             |
|  R√©sultat                |  Mod√®le entra√Æn√© sauvegard√© sous format PyTorch (.pt) pr√™t pour √©valuation               |


