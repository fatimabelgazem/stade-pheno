# EntraÃ®nement du modÃ¨le
Cette section dÃ©taille le processus d'entraÃ®nement du modÃ¨le de dÃ©tection pour le projet **PhÃ©noRendement**. Nous avons adoptÃ© une approche en deux Ã©tapes pour maximiser la prÃ©cision tout en optimisant l'utilisation des ressources.

## ğŸ§  2.1 - StratÃ©gie d'entraÃ®nement
Notre stratÃ©gie d'entraÃ®nement repose sur le transfer learning (apprentissage par transfert) :

- **ğŸ¥‡ Ã‰tape 1 :**  PrÃ©-entraÃ®nement sur un dataset gÃ©nÃ©rique de plantes
- **ğŸ¥ˆ Ã‰tape 2 :**  Fine-tuning sur notre dataset spÃ©cifique d'orangers

Cette approche nous permet de bÃ©nÃ©ficier des connaissances gÃ©nÃ©rales sur la dÃ©tection d'Ã©lÃ©ments de plantes, tout en spÃ©cialisant notre modÃ¨le pour notre cas d'usage prÃ©cis.

# ğŸ§  2.2 - Architecture YOLOv8
YOLOv8 est basÃ© sur une architecture de rÃ©seau neuronal avancÃ©e qui se compose de trois composants principaux :

ğŸ”¹ **Backbone (RÃ©seau dorsal) :**

Le backbone est le rÃ©seau neuronal convolutif **(CNN)** responsable de l'extraction des caractÃ©ristiques Ã  partir de l'image d'entrÃ©e. **YOLOv8** utilise un backbone **CSPDarknet53** personnalisÃ©, qui emploie des connexions partielles entre Ã©tapes **(cross-stage partial connections)** pour amÃ©liorer la circulation de l'information entre les couches et augmenter la prÃ©cision.

ğŸ”¹ **Neck (Cou) :**

Le neck, Ã©galement connu sous le nom d'extracteur de caractÃ©ristiques, fusionne les cartes de caractÃ©ristiques provenant de diffÃ©rentes Ã©tapes du backbone pour capturer des informations Ã  diverses Ã©chelles. L'architecture **YOLOv8** utilise un module **C2f** innovant au lieu du traditionnel **Feature Pyramid Network (FPN)**. Ce module combine des caractÃ©ristiques sÃ©mantiques de haut niveau avec des informations spatiales de bas niveau, ce qui conduit Ã  une meilleure prÃ©cision de dÃ©tection, en particulier pour les petits objets.

ğŸ”¹ **Head (TÃªte) :**
La tÃªte est responsable des prÃ©dictions. **YOLOv8** emploie plusieurs modules de dÃ©tection qui prÃ©disent les boÃ®tes englobantes (bounding boxes), les scores d'objectivitÃ© (objectness scores) et les probabilitÃ©s de classe pour chaque cellule de la grille dans la carte de caractÃ©ristiques. Ces prÃ©dictions sont ensuite agrÃ©gÃ©es pour obtenir les dÃ©tections finales.

<p align="center">
  <img src={require('/static/img/MLops/yolov8-architecture-detail.png').default} alt="Architecture dÃ©taillÃ©e de YOLOv8" width="600px" />
</p>

### ğŸ”¹ Avantages de cette architecture

 - **EfficacitÃ©** : Traitement rapide des images, permettant une dÃ©tection en temps rÃ©el
 - **PrÃ©cision** : TrÃ¨s bonne performance sur les objets de diffÃ©rentes tailles
 - **FlexibilitÃ©** : Plusieurs variantes (nano, small, medium, large, x-large) adaptÃ©es Ã  diffÃ©rents contextes

### ğŸ”¹ FonctionnalitÃ©s clÃ©s

- **DÃ©tection multi-Ã©chelle** : CapacitÃ© Ã  dÃ©tecter des objets de tailles variÃ©es
- **MÃ©canisme d'attention** : Pour se concentrer sur les rÃ©gions importantes de l'image
- **Augmentation d'ancrage** : Pour amÃ©liorer la stabilitÃ© de l'entraÃ®nement

Cette architecture sophistiquÃ©e fait de YOLOv8 un excellent choix pour notre tÃ¢che de dÃ©tection des stades phÃ©nologiques des orangers, offrant un bon Ã©quilibre entre vitesse et prÃ©cision.








# ğŸ” 2.3 - ModÃ¨le de base

-  **ğŸ“Š Architecture :**  YOLOv8m (medium)
- **ğŸŒ± PrÃ©-entraÃ®nement initial :**  Sur le dataset "Nature3: Leaf, Flower, and Fruit Detection"
- **ğŸ“ˆ Avantages :** 
    - Architecture efficace pour la dÃ©tection d'objets en temps rÃ©el.
    - Version "medium" offrant un bon Ã©quilibre entre prÃ©cision et vitesse d'infÃ©rence.
    - CapacitÃ© prouvÃ©e sur les tÃ¢ches de dÃ©tection d'Ã©lÃ©ments naturels.

## âš™ï¸ 2.4 - Configuration d'entraÃ®nement
Nous avons utilisÃ© MLflow pour suivre l'Ã©volution de notre entraÃ®nement et gÃ©rer les expÃ©riences :
``` bash
pythonimport mlflow
import os
import pandas as pd

# Initialisation de MLflow
mlflow.set_tracking_uri("file:///kaggle/working/mlruns")
mlflow.set_experiment("YOLOv8_StadePheno1")
```
### ğŸ”§ HyperparamÃ¨tres principaux :

| ParamÃ¨tre    | Valeur                                                   | 
|--------------|----------------------------------------------------------|
| model_path   |/kaggle/input/modellast43/tensorflow2/default/1/last.pt   |
| epochs       | 100                                                      |
| imgsz        | 800                                                      |
| task         | detect                                                   |
| data         | /kaggle/working/datasets/Stade_Pheno_Dataset-3/data.yaml |
| resume       | True 

## ğŸš€ 2.5 - Processus d'entraÃ®nement
L'entraÃ®nement a Ã©tÃ© exÃ©cutÃ© dans un environnement Kaggle pour bÃ©nÃ©ficier de l'accÃ©lÃ©ration GPU :
``` bash
with mlflow.start_run(run_name="yolov8m_custom_pretrained") as run:
    # Log des hyperparamÃ¨tres
    mlflow.log_param("model_path", "/kaggle/input/modellast43/tensorflow2/default/1/last.pt")
    mlflow.log_param("epochs", 100)
    mlflow.log_param("imgsz", 800)
    
    # Lancement de l'entraÃ®nement YOLOv8
    !yolo task=detect mode=train \
        model=/kaggle/input/modellast43/tensorflow2/default/1/last.pt \
        data=/kaggle/working/datasets/Stade_Pheno_Dataset-3/data.yaml \
        epochs=100 imgsz=800 resume=True

```
### ğŸ“Š Suivi des performances :
Pour assurer une traÃ§abilitÃ© complÃ¨te, nous avons capturÃ© les mÃ©triques clÃ©s Ã  la fin de l'entraÃ®nement :
``` bash 
# Extraction et log des mÃ©triques
result_file = '/kaggle/working/datasets/runs/detect/train/results.csv'
if os.path.exists(result_file):
    df = pd.read_csv(result_file)
    last_row = df.iloc[-1]
    for metric_name, value in last_row.items():
        cleaned_metric_name = metric_name.replace("(", "_").replace(")", "_")
        mlflow.log_metric(cleaned_metric_name, value)

# Log des artifacts (modÃ¨les, courbes, etc.)
mlflow.log_artifacts('/kaggle/working/datasets/runs/detect/train')

```
